{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from cnn1d.config import Config\n",
    "from cnn1d.dataset import CustomDataset, get_df\n",
    "from cnn1d.train import get_recall, train_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\innopolis2022\\cnn1d_train_val_.ipynb Ячейка 2\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/innopolis2022/cnn1d_train_val_.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m dataloader_train \u001b[39m=\u001b[39m DataLoader(dataset_train, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, sampler\u001b[39m=\u001b[39mRandomSampler(dataset_train),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/innopolis2022/cnn1d_train_val_.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)    \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/innopolis2022/cnn1d_train_val_.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m dataloader_val \u001b[39m=\u001b[39m DataLoader(dataset_val, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)    \n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/innopolis2022/cnn1d_train_val_.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m model,epochs_loss\u001b[39m=\u001b[39mtrain_model(drpt,dataloader_train,dataloader_val);\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/innopolis2022/cnn1d_train_val_.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m recall,y_pred_valid \u001b[39m=\u001b[39m get_recall(model, dataloader_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/innopolis2022/cnn1d_train_val_.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m cm\u001b[39m=\u001b[39mconfusion_matrix(y_true\u001b[39m=\u001b[39my_val,y_pred\u001b[39m=\u001b[39my_pred_valid)\n",
      "File \u001b[1;32md:\\Projects\\innopolis2022\\cnn1d\\train.py:64\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(drpt, dataloader_train, dataloader_val)\u001b[0m\n\u001b[0;32m     62\u001b[0m preds \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     63\u001b[0m loss_value \u001b[39m=\u001b[39m loss(preds, y)\n\u001b[1;32m---> 64\u001b[0m loss_value\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     65\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(\n\u001b[0;32m     66\u001b[0m     model\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, norm_type\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, error_if_nonfinite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Programs\\anaconda3\\envs\\py38dl\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32md:\\Programs\\anaconda3\\envs\\py38dl\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()\n",
    "\n",
    "\n",
    "\n",
    "X_train,y_train=get_df(Config.path_train)\n",
    "#columns=X_train.columns\n",
    "FOLDS=5\n",
    "kfolds = KFold(n_splits=FOLDS)\n",
    "\n",
    "drpt_res=dict()\n",
    "#t=tqdm(np.round(np.arange(0.1,0.8,0.05),2))\n",
    "result=defaultdict(lambda :{'recall':[],'cm':[],'epochs_loss':[]})\n",
    "#for drpt in t:\n",
    "drpt=0.5\n",
    "k=0\n",
    "splits = kfolds.split(X_train,y_train)    \n",
    "errors=defaultdict(lambda: defaultdict(lambda: 0))   \n",
    "t=tqdm(list(splits))\n",
    "for train_index, valid_index in t:    \n",
    "    X_tr, X_val = X_train[train_index], X_train[valid_index]\n",
    "    y_tr, y_val = y_train[train_index], y_train[valid_index]    \n",
    "\n",
    "    labels,counts=np.unique(y_tr, return_counts=True)\n",
    "    _max=np.max(counts)*2\n",
    "    sampling_strategy={label:_max  for label in labels }#if label==0 else int(_max+_max*0.4)\n",
    "    smote = SMOTE(random_state=42, sampling_strategy=sampling_strategy, n_jobs=-1)  \n",
    "    X_tr, y_tr = smote.fit_resample(X_tr, y_tr)\n",
    "\n",
    "    dataset_train=CustomDataset(X_tr,y_tr,'Train',True)\n",
    "    dataset_val=CustomDataset(X_val,y_val,'Val',False)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=128, sampler=RandomSampler(dataset_train),\n",
    "                                  shuffle=False, num_workers=0, pin_memory=True)    \n",
    "    dataloader_val = DataLoader(dataset_val, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)    \n",
    "    \n",
    "    model,epochs_loss=train_model(drpt,dataloader_train,dataloader_val);\n",
    "    \n",
    "    recall,y_pred_valid = get_recall(model, dataloader_val)\n",
    "    cm=confusion_matrix(y_true=y_val,y_pred=y_pred_valid)\n",
    "    result[drpt]['recall'].append(recall)\n",
    "    result[drpt]['cm'].append(cm)\n",
    "    result[drpt]['epochs_loss'].append(epochs_loss)     \n",
    "    \n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    t.set_postfix(avg_recall=result[drpt]['recall']) \n",
    "    #[tensor(0.9576), tensor(0.9545), tensor(0.9596), tensor(0.9545), tensor(0.9513)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa7b17b3d2e25d62fb59d89e9f7d3c178175e1f697b7aeeb95820fb257661bd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
